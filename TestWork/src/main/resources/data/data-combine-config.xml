<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<property>
		<name>hdfsUsername</name>
		<value>streamsadmin</value>
		<description>HDFS文件系统访问的用户名(GPFS文件系统这个配置项不用)</description>
	</property>
    <property>
		<name>ifNeedCombineFile</name>
		<value>true</value>
		<description>是否需要文件合并</description>
	</property>
    <property>
		<name>inputFileDir</name>
		<value>/home/hadoop/data/HW_LteXdrCollect/sourcedata/</value>
		<description>
			本地测试目录：D:/1/sourceDir/
			GN数据入HDFS合并程序读源数据的目录(Linux系统路径,必须以斜扛结尾)，默认配置值为：/home/hadoop/data/streamFileSink/
			GN数据入GPFS合并程序读源数据的目录(Linux系统路径,必须以斜扛结尾)，默认配置值为：/home/hadoop/data/dataCombineHdfs/finishData/
			GI数据入HDFS合并程序读源数据的目录(Linux系统路径,必须以斜扛结尾)，默认配置值为：/home/hadoop/data/bgdataweb/gi/gidata/xm/
		</description>
	</property>
    <property>
		<name>dataSourceFileSuffixName</name>
		<value>.txt</value>
		<description>数据源文件的后缀名</description>
	</property>
    <property>
		<name>ctlSourceFileSuffixName</name>
		<value>.txt.chk</value>
		<description>控制源文件的后缀名</description>
	</property>
    <property>
		<name>ifHdfsEnvironmentIsTest</name>
		<value>false</value>
		<description>HDFS环境是否是测试环境</description>
	</property>
    <property>
		<name>ifUseReadRecordFileOfDate</name>
		<value>true</value>
		<description>
			合并程序启动后，第一次生成的HDFS文件名的时间点是否读上次记录的文件时间点，
			如果不是，则读下面的时间参数：currFileDate值
		</description>
	</property>
    <property>
		<name>currFileDateConf</name>
		<value>0</value>
		<description>合并程序正在处理的当前时间点的文件(20140707_17)，默认值为0，可配置为你想要的时间点</description>
	</property>
    <property>
		<name>ifNeedMvDataSourceFile</name>
		<value>true</value>
		<description>合并程序处理完一个文件后，数据源文件（CSV）是否需要移动目录</description>
	</property>
    <property>
		<name>mvSourceFileToDestDire</name>
		<value>/home/hadoop/data/HW_LteXdrCollect/sortdata/</value>
		<description>
			源文件合并完入HDFS后移动的目的目录（这个数据做为GPFS源数据目录），以斜扛结尾，默认值为：/home/hadoop/data/dataCombineHdfs/finishData/
			源文件合并完入GPFS后移动的目的目录，以斜扛结尾，默认值为：/home/hadoop/data/dataCombineGpfs/finishData/
		</description>
	</property>
    <property>
		<name>ifNeedDeleteDataSourceFile</name>
		<value>false</value>
		<description>合并程序处理完一个文件后，数据源文件（CSV）是否需要删除</description>
	</property>
    <property>
		<name>ifNeedDeleteCtlSourceFile</name>
		<value>false</value>
		<description>合并程序处理完一个文件后，控制源文件（CTL）件是否需要删除</description>
	</property>
    <property>
		<name>splitFileNameForDateTime</name>
		<value>_</value>
		<description>
			截取文件名时间点的分隔符
			例如文件：
			LTE接口文件：FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv,
			GN接口文件：GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv
			MC接口文件：FuJianYiDong-A-IuCS-4-201408061520.txt
		</description>
	</property>
    <property>
		<name>ifDateAndHourTheSameLocation</name>
		<value>true</value>
		<description>
			源数据文件名中的日期与小时是否在同一个位置
			例如文件：
			LTE接口文件false：FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv
			GN接口文件false：GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv
			MC接口文件true：FuJianYiDong-A-IuCS-4-201408061520.txt
		</description>
	</property>
    <property>
		<name>dateLocationAtFileName</name>
		<value>3</value>
		<description>
			文件名日期字符串在文件名中的位置
			LTE数据文件名：FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv以_分隔后，日期位置为3
			GN口数据文件名：GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv以_分隔后，日期位置为4
			MC口数据文件名：FuJianYiDong-A-IuCS-4-201408061520.txt以-分隔后，日期位置为4
		</description>
	</property>
    <property>
		<name>dateSubStringBegin</name>
		<value>0</value>
		<description>
			文件名日期字符串在文件名中的位置
			LTE数据文件名FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv以_分隔后，日期位置为3,日期字符串为20140708
			GN口数据文件名GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv以_分隔后，日期位置为4,日期字符串为20131218
			MC口数据文件名：FuJianYiDong-A-IuCS-4-201408061520.txt以-分隔后，日期位置为4，日期字符串为20140806
			日期字符串截取的开始位置都为0
		</description>
	</property>
    <property>
		<name>dateSubStringEnd</name>
		<value>8</value>
		<description>
			文件名日期字符串在文件名中的位置
			LTE数据文件名FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv以_分隔后，日期位置为3,日期字符串为20140708
			GN口数据文件名GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv以_分隔后，日期位置为4,日期字符串为20131218
			MC口数据文件名：FuJianYiDong-A-IuCS-4-201408061520.txt以-分隔后，日期位置为4，日期字符串为20140806
			日期字符串截取的结束位置都为8
		</description>
	</property>
    <property>
		<name>hourLocationAtFileName</name>
		<value>3</value>
		<description>
			文件名小时字符串在文件名中的位置
			LTE数据文件名FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv以_分隔后，小时位置为4
			GN口数据文件名GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv以_分隔后，小时位置为5
			MC口数据文件名：FuJianYiDong-A-IuCS-4-201408061520.txt以-分隔后，小时位置为4
		</description>
	</property>
    <property>
		<name>hourSubStringBegin</name>
		<value>8</value>
		<description>
			文件名日期字符串在文件名中的位置
			LTE数据文件名FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv以_分隔后，小时位置为4,小时字符串为100700
			GN口数据文件名GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv以_分隔后，小时位置为5,小时字符串为105600
			MC口数据文件名：FuJianYiDong-A-IuCS-4-201408061520.txt以-分隔后，小时位置为4,小时字符串为1520
			小时字符串截取的开始位置都为8
		</description>
	</property>
    <property>
		<name>hourSubStringEnd</name>
		<value>10</value>
		<description>
			文件名日期字符串在文件名中的位置
			LTE数据文件名FZLTE001_s1u100_17_20140708_100700_20140708_100759.csv以_分隔后，小时位置为4,小时字符串为100700
			GN口数据文件名GnC64_http_dnssession_60_20131218_105600_20131218_105659.csv以_分隔后，小时位置为5,小时字符串为105600
			MC口数据文件名：FuJianYiDong-A-IuCS-4-201408061520.txt以-分隔后，小时位置为4,小时字符串为1520
			小时字符串截取的结束位置都为10
		</description>
	</property>
    <property>
		<name>fileTypeTotalConfig</name>
		<value>HTTP,FTP,S6A</value>
		<description>
			pdp,ip,http_dnssession,http_netsession,mms,ftp,mail,voip,rtsp,im,p2p
			程序是否使用文件接口类型配置，目前程序支持多种接口文件
			GN口数据为三种接口类型文件：PDP,IP,HTTP
			LTE数据有11种接口类型文件：s1mme,s1u100,s1u101,s1u102,s1u103,s1u104,s1u105,s1u106,s1u107,s1u108,s1u109
			MC口数据只有一种接口类型文件：FuJianYiDong-A-IuCS
		</description>
	</property>
    <property>
		<name>fileTypePath</name>
		<value>HTTP,FTP,S6A</value>
		<description>
			pdp,ip,http_dnssession,http_netsession,mms,ftp,mail,voip,rtsp,im,p2p
			程序是否使用文件接口类型配置，目前程序支持多种接口文件
			GN口数据为三种接口类型文件：PDP,IP,HTTP
			LTE数据有11种接口类型文件：s1mme,s1u100,s1u101,s1u102,s1u103,s1u104,s1u105,s1u106,s1u107,s1u108,s1u109
			MC口数据只有一种接口类型文件：FuJianYiDong-A-IuCS
		</description>
	</property>
    <property>
		<name>fileMiddleName</name>
		<value>DATA1</value>
		<description>GPFS合并程序合并成大文件后，文件名中间部分标志，标识数据属于哪个节点（HDFS合并程序目前没有这个配置项）
		</description>
	</property>
    <property>
		<name>ifHdfsFileNameHasTmp</name>
		<value>fase</value>
		<description>合并文件过程的中间文件是否以TMP结尾</description>
	</property>
    <property>
		<name>hdfsFileNameTmpSuffix</name>
		<value>.tmp</value>
		<description>合并文件过程的中间文件后缀名</description>
	</property>
	<property>
		<name>hdfsTmpPathList</name>
		<value>
			/home/hadoop/data/dataCombineGpfs/hw_lte/tmpdata/
		</value>
		<description>
			/home/hadoop/data/gpfs/yz_newland_base/gpfsdata/hw_lte/tmpdata/
			/home/hadoop/data/HW_LteXdrCombine/tmpdata/
			hdfs://bch:8020/bigData/testDataCollect/tmp4/1/
			,
			hdfs://bch:8020/bigData/testDataCollect/tmp4/2/
			合并文件过程的中间目录列表，每行一个目录，目录之间用“,”隔开
			合并文件过程的中间目录，目录要以斜找结尾
			HDFS目录：hdfs://bch:8020/bigData/dataCollector/tmp1/
			QZ1:tmp1 XM1:tmp2 HD1:tmp3 JS:tmp4 YC:tmp5 QZ2:tmp6
			HD2:tmp7 XM2:tmp8 HD3:tmp9 QZ3:tmp10 QZ4:tmp11 QZ5:tmp12
			GPFS中间目录（中间目录只有一个）：/home/hadoop/data/gpfs/yz_newland_base/gpfsdata/gn_cdr/tmp/
		</description>
	</property>
    <property>
		<name>hdfsFinishPathList</name>
		<value>
			/home/hadoop/data/dataCombineGpfs/hw_lte/
		</value>
		<description>
			/home/hadoop/data/gpfs/yz_newland_base/gpfsdata/hw_lte/
			/home/hadoop/data/HW_LteXdrCombine/
			hdfs://bch:8020/bigData/testDataCollect/etl-4/1/
			,
			hdfs://bch:8020/bigData/testDataCollect/etl-4/2/
			合并文件过程的最终目录列表，每行一个目录，目录之间用“,”隔开
			合并文件完成后的存放目录，目录要以斜找结尾
			HDFS目录：hdfs://bch:8020/bigData/dataCollector/etl-1/
			（测试：hdfs://10.1.4.53:8020 生产：hdfs://bch:8020）
			QZ1:etl-1 XM1:etl-2 HD1:etl-3 JS:etl-4 YC:etl-5 QZ2:etl-6
			HD2:etl-7 XM2:etl-8 HD3:etl-9 QZ3:etl-10 QZ4:etl-11 QZ5:etl-12
			GPFS目录：/home/hadoop/data/gpfs/yz_newland_base/gpfsdata/gn_cdr/
		</description>
	</property>
    <property>
		<name>ifCombineFileWriteLine</name>
		<value>true</value>
		<description>合并文件时在写文件时是否是一行一行写</description>
	</property>
    <property>
		<name>writeHdfsBufferSize</name>
		<value>5</value>
		<description>合并文件时在写文件的缓冲区大小，单位为M</description>
	</property>
    <property>
		<name>ifNeedUtapEvent</name>
		<value>true</value>
		<description>是否需要插入UTAP事件</description>
	</property>
    <property>
		<name>utapEventRuleId</name>
		<value>72037</value>
		<description>
			utap事件规则event_rule_id前缀
			GN口数据：
			QZ1(IP:1):70101 XM1(IP:58):70111 HD1(IP:6):70121 JS(IP:54):70131 YC(IP:55):70141
			QZ2(IP:2):70151
			HD2(IP:8):70161 XM2(IP:59):70171 HD3(IP:9):70181 QZ3(IP:3):70191 QZ4(IP:4):70192
			QZ5(IP:5):70193
			MC口数据：
			QZ1(IP:1):72004 XM1(IP:58):72002 HD1(IP:6):72009 JS(IP:54):72000 YC(IP:55):72001
			QZ2(IP:2):72005
			HD2(IP:8):72010 XM2(IP:59):72003 HD3(IP:9):72011 QZ3(IP:3):72006 QZ4(IP:4):72007
			QZ5(IP:5):72008
		</description>
	</property>
    <property>
		<name>utapEventCode</name>
		<value>82037</value>
		<description>
			utap事件码event_code前缀
			GN口数据：
			QZ1(IP:1):80911 XM1(IP:58):81911 HD1(IP:6):82911 JS(IP:54):83911 YC(IP:55):84911
			QZ2(IP:2):85911
			HD2(IP:8):86911 XM2(IP:59):87911 HD3(IP:9):88911 QZ3(IP:3):89911 QZ4(IP:4):89921
			QZ5(IP:5):89931
			MC口数据：
			QZ1(IP:1):82004 XM1(IP:58):82002 HD1(IP:6):82009 JS(IP:54):82000 YC(IP:55):82001
			QZ2(IP:2):82005
			HD2(IP:8):82010 XM2(IP:59):82003 HD3(IP:9):82011 qz3(IP:3):82006 QZ4(IP:4):82007
			QZ5(IP:5):82008
		</description>
	</property>
    <property>
		<name>maxCombineThreadNum</name>
		<value>5</value>
		<description>合并程序的最大线程数 </description>
	</property>
    <property>
		<name>ifNeedAddField</name>
		<value>false</value>
		<description>是否需要增加字段。当上层的流处理出现故障时，需要手动设置为True，对缺漏的字段进行添加。
		</description>
	</property>
    <property>
		<name>needAddFieldFileType</name>
		<value>ip;http_netsession;rtsp</value>
		<description>
			选择pdp,ip,http_dnssession,http_netsession,mms,ftp,mail,voip,rtsp,im,p2p
			11种文件接口类型需要增加字段的文件类型,用";"隔开
		</description>
	</property>
    <property>
		<name>needAddFieldString</name>
		<value>,,;,,,,,,,;,,,,,,,</value>
		<description>需要增加字段的接口文件的需要增加的对应字段，用";"隔开 </description>
	</property>
    <property>
		<name>driverClassName</name>
		<value>oracle.jdbc.OracleDriver</value>
		<description>数据库驱动类 </description>
	</property>
    <property>
		<name>urlDb</name>
		<value>jdbc:oracle:thin:@10.46.61.70:1521:hdjk</value>
		<description>数据库访问的URL </description>
	</property>
    <property>
		<name>usernameDb</name>
		<value>utaph</value>
		<description>数据库访问的用户名</description>
	</property>
    <property>
		<name>passwordDb</name>
		<value>fbi_utaph1</value>
		<description>数据库访问的密码 </description>
	</property>
    <property>
		<name>ifModifyDfsSocketTimeout</name>
		<value>true</value>
		<description>是否修改Dfs client端socket超时的默认值 </description>
	</property>
    <property>
		<name>dfs.socket.timeout</name>
		<value>180000</value>
		<description>Dfs client端socket超时 </description>
	</property>
    <property>
		<name>ifModifyDfsDatanodeSocketWriteTimeout</name>
		<value>false</value>
		<description>是否修改Dfs client端写超时的默认值 </description>
	</property>
    <property>
		<name>dfs.datanode.socket.write.timeout</name>
		<value>180000</value>
		<description>Dfs client端写超时 </description>
	</property>
    <property>
		<name>errorFileDir</name>
		<value>/home/hadoop/data/dataCombineGpfs/hw_lte/data/errorFile/</value>
		<description>
			/home/hadoop/data/gpfs/yz_newland_base/gpfsdata/hw_lte/errorFile/
			合并文件时读入的错误文件时对其相应处理为移到另外一个存放错误文件的目录
			HDFS合并程序错误数据目录为：/home/hadoop/data/dataCombineHdfs/errorFile/
			GPFS合并程序错误数据目录为：/home/hadoop/data/dataCombineGpfs/errorFile/
		</description>
	</property>
    <property>
		<name>ifDataCombineToHdfs</name>
		<value>false</value>
		<description>合并程序是否是入HDFS </description>
	</property>
    <property>
		<name>ifDataCombineToGpfs</name>
		<value>true</value>
		<description>合并程序是否是入GPFS </description>
	</property>
    <property>
		<name>checkIntervalTime</name>
		<value>600</value>
		<description>设置定时检验路径是否出错的时间间隔，单位为秒。 </description>
	</property>
    <property>
		<name>multiOrSinglePathToUTAp</name>
		<value>true</value>
		<description>
			设置是所有路径写入完成触发UTAP事件
			还是只要有一个路径完成就触发UTAP事件，
			true为所有路径写入完成触发
		</description>
	</property>
    <property>
		<name>ifSourceDataIsBinary</name>
		<value>false</value>
		<description>源数据是否是二进制文件</description>
	</property>
    <property>
		<name>ifBinaryDataToString</name>
		<value>false</value>
		<description>二进制文件是否要转为字符串</description>
	</property>
    <property>
		<name>ifFilterSpecificFileName</name>
		<value>false</value>
		<description>是否过滤出含有特定字符串的文件名</description>
	</property>
	<property>
		<name>multiOrSinglePathToUTAp</name>
		<value>true</value>
		<description>
			设置是所有路径写入完成触发UTAP事件
			还是只要有一个路径完成就触发UTAP事件，
			true为所有路径写入完成触发
		</description>
	</property>
    <property>
		<name>ifSourceDataIsBinary</name>
		<value>false</value>
		<description>源数据是否是二进制文件</description>
	</property>
    <property>
		<name>ifBinaryDataToString</name>
		<value>false</value>
		<description>二进制文件是否要转为字符串</description>
	</property>
    <property>
		<name>ifFilterSpecificFileName</name>
		<value>false</value>
		<description>是否过滤出含有特定字符串的文件名</description>
	</property>
    <property>
		<name>filterSpecificFileName</name>
		<value>AB</value>
		<description>过滤出含有特定字符串的文件名</description>
	</property>
    <property>
		<name>writeFileMaxLines</name>
		<value>20000</value>
		<description>一次写入文件的最大行数</description>
	</property>
    <property>
		<name>ifCombineByShell</name>
		<value>true</value>
		<description> 设置合并时是否使用Shell指令进行合并</description>
	</property>
    <property>
		<name>ifCombineInTotal</name>
		<value>false</value>
		<description>设置合并时是否使用Shell批量合并处理</description>
	</property>
</configuration>