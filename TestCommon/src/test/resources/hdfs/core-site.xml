<?xml version="1.0" encoding="UTF-8"?>
<configuration>
<property>
<name>hadoop.proxyuser.mapred.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.nas.task.nodes</name>
<value></value>
</property>
<property>
<name>cas.conf.serverName.on</name>
<value>https://10.1.12.80:20026/HDFS/NameNode/172/</value>
</property>
<property>
<name>hadoop.security.auth_to_local</name>
<value>RULE:[1:$1]
RULE:[2:$1]
DEFAULT</value>
</property>
<property>
<name>io.compression.codec.lzc.class</name>
<value>com.huawei.hadoop.datasight.io.compress.lzc.ZCodec</value>
</property>
<property>
<name>hadoop.proxyuser.batch.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x2.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.ftpserver.hosts</name>
<value>*</value>
</property>
<property>
<name>ipc.ping.interval</name>
<value>60000</value>
</property>
<property>
<name>hadoop.proxyuser.impala.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.obs.auth.agency-mapping.localpath</name>
<value>/opt/Bigdata/agency-mapping.properties</value>
</property>
<property>
<name>fs.obs.security.provider</name>
<value>com.huawei.mrs.MrsObsCredentialsProvider</value>
</property>
<property>
<name>fs.s3a.signing-algorithm</name>
<value>S3SignerType</value>
</property>
<property>
<name>fs.obs.threads.max</name>
<value>20</value>
</property>
<property>
<name>fs.obs.list.threads.core</name>
<value>40</value>
</property>
<property>
<name>hadoop.proxyuser.HTTP.hosts</name>
<value>*</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.quorum</name>
<value>edc-bch-mn03:24002,edc-bch-mn02:24002,edc-bch-mn01:24002</value>
</property>
<property>
<name>hadoop.proxyuser.spark.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.AbstractFileSystem.alluxio.impl</name>
<value>alluxio.hadoop.AlluxioFileSystem</value>
</property>
<property>
<name>hadoop.proxyuser.spark3.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.alluxio.impl</name>
<value>alluxio.hadoop.FileSystem</value>
</property>
<property>
<name>fs.obs.socket.recv.buffer</name>
<value>262144</value>
</property>
<property>
<name>hadoop.proxyuser.spark2.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark4.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.loader.groups</name>
<value>*</value>
</property>
<property>
<name>fs.obs.metrics.switch</name>
<value>true</value>
</property>
<property>
<name>hadoop.proxyuser._default_proxy_user_.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase1.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase3.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.da200.install.path</name>
<value>/opt/DA200/compress_tools/libz/libzagent.so</value>
</property>
<property>
<name>hadoop.http.kerberos.internal.spnego.principal</name>
<value>HTTP/${HOST_NAME}@HADOOP.COM</value>
</property>
<property>
<name>hadoop.proxyuser.mapred.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.security.logout.ui.enable</name>
<value>true</value>
</property>
<property>
<name>hadoop.security.group.mapping</name>
<value>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</value>
</property>
<property>
<name>hadoop.ssl.keystores.factory.class</name>
<value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
</property>
<property>
<name>hadoop.zk.num-retries</name>
<value>1000</value>
</property>
<property>
<name>ha.zookeeper.quorum</name>
<value>edc-bch-mn03:24002,edc-bch-mn02:24002,edc-bch-mn01:24002</value>
</property>
<property>
<name>hadoop.http.filter.initializers</name>
<value>com.huawei.hadoop.adapter.sso.FlowCtrlFilter,com.huawei.hadoop.adapter.sso.XSSFilterInitializer,com.huawei.hadoop.adapter.sso.InternalSpnegoFilter,com.huawei.hadoop.adapter.sso.CASClientFilter,com.huawei.hadoop.adapter.sso.WebHDFSTokenSetterFilterInitializer,com.huawei.hadoop.adapter.sso.WebHDFSLocationSetterFilterInitializer,com.huawei.hadoop.adapter.sso.LogoutFilterInitializer</value>
</property>
<property>
<name>fs.obs.list.parallel.factor</name>
<value>80</value>
</property>
<property>
<name>ipc.server.read.threadpool.size</name>
<value>5</value>
</property>
<property>
<name>hadoop.proxyuser.miner.groups</name>
<value>*</value>
</property>
<property>
<name>ipc.client.rpc-timeout.ms</name>
<value>300000</value>
</property>
<property>
<name>hadoop.proxyuser.miner.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.pollux.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.zk.acl</name>
<value>world:anyone:r,sasl:hdfs/hadoop.hadoop.com@HADOOP.COM:rwcda</value>
</property>
<property>
<name>fs.obs.socket.send.buffer</name>
<value>262144</value>
</property>
<property>
<name>sas.plugin.enable</name>
<value>false</value>
</property>
<property>
<name>hadoop.proxyuser.omm.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.ssl.enabled.protocols</name>
<value>TLSv1.2</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x3.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark1.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x1.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x4.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.knox.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hdfs.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase3.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.trash.interval</name>
<value>1440</value>
</property>
<property>
<name>hadoop.proxyuser.hive4.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.http.authentication.center.listener</name>
<value>org.jasig.cas.client.session.SingleSignOutHttpSessionListener</value>
</property>
<property>
<name>fs.obs.secret.key</name>
<value></value>
</property>
<property>
<name>hadoop.proxyuser.hive2.hosts</name>
<value>*</value>
</property>
<property>
<name>ipc.server.listen.queue.size</name>
<value>128</value>
</property>
<property>
<name>clientPort</name>
<value>24002</value>
</property>
<property>
<name>fs.viewfs.mounttable.ClusterX.homedir</name>
<value>/</value>
</property>
<property>
<name>hadoop.proxyuser.hive1.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.knox.groups</name>
<value>*</value>
</property>
<property>
<name>fs.viewfs.rename.strategy</name>
<value>SAME_FILESYSTEM_ACROSS_MOUNTPOINT</value>
</property>
<property>
<name>hadoop.proxyuser.hbase.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hive.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.client.resolve.topology.enabled</name>
<value>true</value>
</property>
<property>
<name>fs.s3a.security.credential.provider.path</name>
<value>localjceks://file${hadoop.home.dir}/etc/hadoop/locals3.jceks</value>
</property>
<property>
<name>hadoop.spnego.allowed.ips</name>
<value>.*</value>
</property>
<property>
<name>hadoop.security.instrumentation.requires.admin</name>
<value>true</value>
</property>
<property>
<name>hadoop.security.groups.shell.command.timeout</name>
<value>60s</value>
</property>
<property>
<name>fs.obs.block.size</name>
<value>134217728</value>
</property>
<property>
<name>ha.zookeeper.acl</name>
<value>world:anyone:r,sasl:hdfs/hadoop.hadoop.com@HADOOP.COM:rwcda</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x4.hosts</name>
<value>*</value>
</property>
<property>
<name>io.file.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>ipc.client.ping</name>
<value>true</value>
</property>
<property>
<name>hadoop.proxyuser.hetuserver.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase4.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.oozie.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hive1.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/bi/data</value>
</property>
<property>
<name>fs.nas.impl</name>
<value>com.huawei.nasfilesystem.ShareNASFileSystem</value>
</property>
<property>
<name>fs.obs.access.key</name>
<value></value>
</property>
<property>
<name>hadoop.proxyuser.hbase2.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.oozie.groups</name>
<value>*</value>
</property>
<property>
<name>fs.obs.endpoint</name>
<value></value>
</property>
<property>
<name>fs.obs.metrics.consumer</name>
<value>org.apache.hadoop.fs.obs.metrics.OBSAMetricsProvider</value>
</property>
<property>
<name>hadoop.proxyuser.spark1.groups</name>
<value>*</value>
</property>
<property>
<name>fs.obs.server-side-encryption-key</name>
<value></value>
</property>
<property>
<name>cas.conf.serverName.off</name>
<value>https://edc-bch-mn02:25003</value>
</property>
<property>
<name>hadoop.proxyuser.solr.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.http.server.MaxRequests</name>
<value>2000</value>
</property>
<property>
<name>hadoop.ssl.require.client.cert</name>
<value>false</value>
</property>
<property>
<name>hadoop.security.openssl.engin.id</name>
<value>kae</value>
</property>
<property>
<name>cas.conf.casServerUrlPrefix.on</name>
<value>https://10.1.12.80:20027/cas/</value>
</property>
<property>
<name>hadoop.security.key.provider.path</name>
<value></value>
</property>
<property>
<name>fs.trash.checkpoint.interval</name>
<value>60</value>
</property>
<property>
<name>hadoop.zk.timeout-ms</name>
<value>90000</value>
</property>
<property>
<name>hadoop.security.authorization</name>
<value>true</value>
</property>
<property>
<name>hadoop.proxyuser.executor.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.solr.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.loader.hosts</name>
<value>*</value>
</property>
<property>
<name>ipc.client.connect.timeout</name>
<value>20000</value>
</property>
<property>
<name>cas.conf.casServerUrlPrefix.off</name>
<value>https://10.1.12.80:20009/cas/</value>
</property>
<property>
<name>fs.obs.write.buffer.size</name>
<value>262144</value>
</property>
<property>
<name>cluster.ip.model</name>
<value>cluster_ip_model=IPV4</value>
</property>
<property>
<name>hadoop.security.authentication</name>
<value>kerberos</value>
</property>
<property>
<name>hadoop.proxyuser.hdfs.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark4.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.obs.buffer.dir</name>
<value>${java.io.tmpdir}/obs</value>
</property>
<property>
<name>hadoop.cluster.rank</name>
<value></value>
</property>
<property>
<name>hadoop.proxyuser.hue.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase1.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.obs.readahead.range</name>
<value>4194304</value>
</property>
<property>
<name>hadoop.proxyuser.hetuserver.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.security.token.service.use_ip</name>
<value>true</value>
</property>
<property>
<name>fs.obs.list.threads.max</name>
<value>80</value>
</property>
<property>
<name>hadoop.security.crypto.implementation.class</name>
<value>com.huawei.hadoop.adapter.security.HadoopCryptoAdapter</value>
</property>
<property>
<name>hadoop.proxyuser.hue.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase4.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.ftpserver.groups</name>
<value>*</value>
</property>
<property>
<name>io.compression.codecs</name>
<value>org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.Lz4Codec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.ZStandardCodec,com.huawei.hadoop.datasight.io.compress.lzc.ZCodec</value>
</property>
<property>
<name>hadoop.proxyuser.hive.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.batch.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.zk.retry-interval-ms</name>
<value>1000</value>
</property>
<property>
<name>hadoop.proxyuser.hive3.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.http.authentication.center</name>
<value>https://10.1.12.80:20009/cas/</value>
</property>
<property>
<name>fs.defaultFS</name>
<value>hdfs://hacluster</value>
</property>
<property>
<name>hadoop.proxyuser.impala.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.ssl.client.conf</name>
<value>ssl-client.xml</value>
</property>
<property>
<name>fs.obs.server-side-encryption-type</name>
<value>NONE</value>
</property>
<property>
<name>fs.nas.mount.dir</name>
<value>/mnt/nfsdata0</value>
</property>
<property>
<name>hadoop.proxyuser._default_proxy_user_.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x2.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.pollux.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x3.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.zk.address</name>
<value>edc-bch-mn03:24002,edc-bch-mn02:24002,edc-bch-mn01:24002</value>
</property>
<property>
<name>ipc.maximum.data.length</name>
<value>268435456</value>
</property>
<property>
<name>fs.AbstractFileSystem.nas.impl</name>
<value>com.huawei.nasfilesystem.WushanFs</value>
</property>
<property>
<name>cas.proxy.switch</name>
<value>true</value>
</property>
<property>
<name>hadoop.ssl.hostname.verifier</name>
<value>ALLOW_ALL</value>
</property>
<property>
<name>hadoop.http.tolerance.time</name>
<value>300000</value>
</property>
<property>
<name>hadoop.http.kerberos.internal.spnego.keytab</name>
<value>/opt/huawei/Bigdata/FusionInsight_HD_8.0.2.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/HTTP.keytab</value>
</property>
<property>
<name>hadoop.security.crypto.codec.classes.aes.ctr.nopadding</name>
<value>org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec</value>
</property>
<property>
<name>hadoop.http.authentication.logout</name>
<value>https://10.1.12.80:20009/cas/logout?service=https://10.1.12.80:20026/HDFS/NameNode/172/dfshealth.html</value>
</property>
<property>
<name>hadoop.proxyuser.hive3.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.ssl.server.conf</name>
<value>ssl-server.xml</value>
</property>
<property>
<name>hadoop.proxyuser.hive2.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hbase.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.spark3.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.hive4.hosts</name>
<value>*</value>
</property>
<property>
<name>fs.obs.read.buffer.size</name>
<value>262144</value>
</property>
<property>
<name>ipc.client.fallback-to-simple-auth-allowed</name>
<value>true</value>
</property>
<property>
<name>fs.AbstractFileSystem.obs.impl</name>
<value>org.apache.hadoop.fs.obs.OBS</value>
</property>
<property>
<name>hadoop.proxyuser.hbase2.groups</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.omm.hosts</name>
<value>*</value>
</property>
<property>
<name>cas.conf.casServerLoginUrl</name>
<value>https://10.1.12.80:20009/cas/login</value>
</property>
<property>
<name>ipc.server.log.slow.rpc</name>
<value>false</value>
</property>
<property>
<name>hadoop.http.server.name</name>
<value>https://edc-bch-mn02:25003</value>
</property>
<property>
<name>ha.zookeeper.session-timeout.ms</name>
<value>90000</value>
</property>
<property>
<name>fs.s3a.connection.ssl.enabled</name>
<value>false</value>
</property>
<property>
<name>hadoop.rpc.protection</name>
<value>privacy</value>
</property>
<property>
<name>hadoop.proxyuser.executor.hosts</name>
<value>*</value>
</property>
<property>
<name>dfs.federation.router.quota.enable</name>
<value>true</value>
</property>
<property>
<name>hadoop.security.credstore.java-keystore-provider.password-file</name>
<value>s3p.file</value>
</property>
<property>
<name>ha.health-monitor.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>hadoop.http.staticuser.user</name>
<value>hdfs</value>
</property>
<property>
<name>hadoop.proxyuser.spark2x1.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.HTTP.groups</name>
<value>*</value>
</property>
<property>
<name>fs.s3a.endpoint</name>
<value></value>
</property>
</configuration>
